{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9faf1186",
   "metadata": {},
   "source": [
    "# Distributed Machine Learning\n",
    "## Wrangle Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b786e67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/23 09:09:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f1bfe",
   "metadata": {},
   "source": [
    "1. Read the case, department, and source data into their own spark dataframes.\n",
    "\n",
    "2. Let's see how writing to the local disk works in spark:\n",
    "\n",
    "- Write the code necessary to store the source data in both csv and json format, store these as sources_csv and sources_json\n",
    "- Inspect your folder structure. What do you notice?\n",
    "3. Inspect the data in your dataframes. \n",
    "- Are the data types appropriate? \n",
    "- Write the code necessary to cast the values to the appropriate types.\n",
    "---------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b029dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "source = spark.read.csv(\"source.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "case = spark.read.csv(\"case.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "dept = spark.read.csv(\"dept.csv\", sep=\",\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a95cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|source_id| source_username|\n",
      "+---------+----------------+\n",
      "|   100137|Merlene Blodgett|\n",
      "|   103582|     Carmen Cura|\n",
      "+---------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c0a154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------------+------------+---------+------------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "|   case_id|case_opened_date|case_closed_date|SLA_due_date|case_late|     num_days_late|case_closed|   dept_division|service_request_type|SLA_days|case_status|source_id|     request_address|council_district|\n",
      "+----------+----------------+----------------+------------+---------+------------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "|1014127332|     1/1/18 0:42|    1/1/18 12:29|9/26/20 0:42|       NO|-998.5087616000001|        YES|Field Operations|        Stray Animal|   999.0|     Closed| svcCRMLS|2315  EL PASO ST,...|               5|\n",
      "+----------+----------------+----------------+------------+---------+------------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82747729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+----------------------+-------------------+\n",
      "|  dept_division|           dept_name|standardized_dept_name|dept_subject_to_SLA|\n",
      "+---------------+--------------------+----------------------+-------------------+\n",
      "|311 Call Center|    Customer Service|      Customer Service|                YES|\n",
      "|          Brush|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "+---------------+--------------------+----------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5839615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- standardized_dept_name: string (nullable = true)\n",
      " |-- dept_subject_to_SLA: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c623ba97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- source_username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa9473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: integer (nullable = true)\n",
      " |-- case_opened_date: string (nullable = true)\n",
      " |-- case_closed_date: string (nullable = true)\n",
      " |-- SLA_due_date: string (nullable = true)\n",
      " |-- case_late: string (nullable = true)\n",
      " |-- num_days_late: double (nullable = true)\n",
      " |-- case_closed: string (nullable = true)\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- service_request_type: string (nullable = true)\n",
      " |-- SLA_days: double (nullable = true)\n",
      " |-- case_status: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- request_address: string (nullable = true)\n",
      " |-- council_district: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf02d6",
   "metadata": {},
   "source": [
    "### Initial prep (case file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea4248f2",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Rename column\n",
    "case = case.withColumnRenamed('SLA_due_date', 'case_due_date')\n",
    "\n",
    "# Convert to better data types\n",
    "case = (\n",
    "    case.withColumn('case_late', col('case_late') == 'YES')\n",
    "    .withColumn('case_closed', col('case_closed') == 'YES')\n",
    ")\n",
    "case = case.withColumn('council_district', format_string('%04d', col('council_district')))\n",
    "case = (\n",
    "    case.withColumn('case_opened_date', to_timestamp(col('case_opened_date'), 'M/d/yy H:mm'))\n",
    "    .withColumn('case_closed_date', to_timestamp(col('case_closed_date'), 'M/d/yy H:mm'))\n",
    "    .withColumn('case_due_date', to_timestamp(col('case_due_date'), 'M/d/yy H:mm'))\n",
    ")\n",
    "\n",
    "# Cleanup text data\n",
    "case = case.withColumn('request_address', lower(trim(col('request_address'))))\n",
    "# Extract zipcode\n",
    "case = case.withColumn('zipcode', regexp_extract(col('request_address'), r'\\d+$', 0))\n",
    "\n",
    "# Create a `case_lifetime` feature\n",
    "case = (\n",
    "    case.withColumn('case_age', datediff(current_timestamp(), 'case_opened_date'))\n",
    "    .withColumn('days_to_closed', datediff('case_closed_date', 'case_opened_date'))\n",
    "    .withColumn('case_lifetime', when(col('case_closed'), col('days_to_closed')).otherwise(col('case_age')))\n",
    "    .drop('case_age', 'days_to_closed')\n",
    ")\n",
    "\n",
    "# Join departments and sources\n",
    "depts = spark.read.csv('dept.csv', header=True, inferSchema=True)\n",
    "sources = spark.read.csv('source.csv', header=True, inferSchema=True)\n",
    "\n",
    "case = case.join(depts, 'dept_division', 'left').join(sources, 'source_id', 'left')\n",
    "\n",
    "# # Train Test Split\n",
    "# train, test = df.randomSplit([.8, .2], seed=123)\n",
    "# train, validate, test = df.randomSplit([.7, .15, .15], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a472c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "422e260f",
   "metadata": {},
   "source": [
    "### 1. How old is the latest (in terms of days past SLA) currently open issue? How long has the oldest (in terms of days since opened) currently opened issue been open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4830182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===>                                                    (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|days_past_due|\n",
      "+-------------+\n",
      "|         1952|\n",
      "|         1952|\n",
      "|         1952|\n",
      "|         1951|\n",
      "|         1949|\n",
      "|         1945|\n",
      "|         1945|\n",
      "|         1944|\n",
      "|         1943|\n",
      "|         1943|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "case.createOrReplaceTempView('case')\n",
    "\n",
    "\n",
    "(spark.sql('''SELECT DATEDIFF(current_timestamp, case_due_date)\n",
    "AS days_past_due \n",
    "FROM case \n",
    "WHERE NOT case_closed \n",
    "ORDER BY days_past_due \n",
    "DESC LIMIT 10;''').show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c930f3",
   "metadata": {},
   "source": [
    "### 2. How many Stray Animal cases are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9b49b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tStray Animal Count: 27361.\n"
     ]
    }
   ],
   "source": [
    "stray_count = case.filter(case.service_request_type == 'Stray Animal').count()\n",
    "print(f'\\n\\tStray Animal Count: {stray_count}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdb2064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|service_request_type|count|\n",
      "+--------------------+-----+\n",
      "|        Stray Animal|27361|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternate solution\n",
    "\n",
    "case.groupBy('service_request_type').count().filter(expr('service_request_type == \"Stray Animal\"')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f223e08",
   "metadata": {},
   "source": [
    "### 3. How many service requests that are assigned to the Field Operations department (dept_division) are not classified as \"Officer Standby\" request type (service_request_type)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b28d74d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tNon-Officer Standby Field Operatons Count: 116295.\n"
     ]
    }
   ],
   "source": [
    "count_field_ops_not_officer_standby = case.filter(case.dept_division == 'Field Operations').filter(case.service_request_type != 'Officer Standby').count()\n",
    "\n",
    "print(f'\\n\\tNon-Officer Standby Field Operatons Count: {count_field_ops_not_officer_standby}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b4dfb",
   "metadata": {},
   "source": [
    "4. Convert the council_district column to a string column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "170329ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = case.withColumn('council_district', format_string('%04d', col('council_district')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009173ab",
   "metadata": {},
   "source": [
    "### 5. Extract the year from the case_closed_date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d04e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------+\n",
      "|   case_closed_date|year(case_closed_date)|\n",
      "+-------------------+----------------------+\n",
      "|2018-01-01 12:29:00|                  2018|\n",
      "|2018-01-03 08:11:00|                  2018|\n",
      "|2018-01-02 07:57:00|                  2018|\n",
      "|2018-01-02 08:13:00|                  2018|\n",
      "|2018-01-01 13:29:00|                  2018|\n",
      "|2018-01-01 14:38:00|                  2018|\n",
      "|2018-01-02 15:32:00|                  2018|\n",
      "|2018-01-02 15:32:00|                  2018|\n",
      "|2018-01-02 15:32:00|                  2018|\n",
      "|2018-01-02 15:32:00|                  2018|\n",
      "|2018-01-02 15:32:00|                  2018|\n",
      "|2018-01-02 15:32:00|                  2018|\n",
      "|2018-01-02 15:33:00|                  2018|\n",
      "|2018-01-02 15:32:00|                  2018|\n",
      "|2018-01-02 15:33:00|                  2018|\n",
      "|2018-01-02 15:33:00|                  2018|\n",
      "|2018-01-02 15:33:00|                  2018|\n",
      "|2018-01-02 15:33:00|                  2018|\n",
      "|2018-01-02 15:33:00|                  2018|\n",
      "|2018-01-02 15:33:00|                  2018|\n",
      "+-------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case.select('case_closed_date', year('case_closed_date')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba480a",
   "metadata": {},
   "source": [
    "### 6. Convert num_days_late from days to hours in new columns num_hours_late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "451c8981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|      num_days_late|     num_hours_late|\n",
      "+-------------------+-------------------+\n",
      "| -998.5087616000001|     -23964.2102784|\n",
      "|-2.0126041669999997|-48.302500007999996|\n",
      "|       -3.022337963|      -72.536111112|\n",
      "|       -15.01148148|      -360.27555552|\n",
      "|0.37216435200000003|  8.931944448000001|\n",
      "|       -29.74398148| -713.8555555199999|\n",
      "|       -14.70673611|      -352.96166664|\n",
      "|       -14.70662037|      -352.95888888|\n",
      "|       -14.70662037|      -352.95888888|\n",
      "|       -14.70649306|      -352.95583344|\n",
      "|       -14.70649306|      -352.95583344|\n",
      "|       -14.70636574|      -352.95277776|\n",
      "|          -14.70625|-352.95000000000005|\n",
      "|       -14.70636574|      -352.95277776|\n",
      "|       -14.70623843|-352.94972232000003|\n",
      "|-14.705891199999998|-352.94138879999997|\n",
      "|       -14.70600694|      -352.94416656|\n",
      "|       -14.70576389|      -352.93833336|\n",
      "|       -14.70576389|      -352.93833336|\n",
      "|       -14.70564815|       -352.9355556|\n",
      "+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case.withColumn('num_hours_late', case.num_days_late * 24).select('num_days_late', 'num_hours_late').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c46ee8",
   "metadata": {},
   "source": [
    "### 7. Join the case data with the source and department data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a63a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "depts = spark.read.csv('dept.csv', header=True, inferSchema=True)\n",
    "sources = spark.read.csv('source.csv', header=True, inferSchema=True)\n",
    "\n",
    "case = case.join(depts, 'dept_division', 'left').join(sources, 'source_id', 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f50a8",
   "metadata": {},
   "source": [
    "### 8. Are there any cases that do not have a request source?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb518b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|sum(is_null)|\n",
      "+------------+\n",
      "|           0|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case.select(case.source_id.isNull().cast('int').alias('is_null')).agg(sum('is_null')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a8d9471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 rows)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternate way\n",
    "case.filter(col('source_id').isNull()).show(vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee9cc7",
   "metadata": {},
   "source": [
    "### 9. What are the top 10 service request types in terms of number of requests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35e796e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+------+\n",
      "|service_request_type            |count |\n",
      "+--------------------------------+------+\n",
      "|No Pickup                       |103340|\n",
      "|Overgrown Yard/Trash            |69451 |\n",
      "|Damaged Cart                    |36113 |\n",
      "|Bandit Signs                    |33316 |\n",
      "|Stray Animal                    |30967 |\n",
      "|Front Or Side Yard Parking      |29676 |\n",
      "|Aggressive Animal(Non-Critical) |29152 |\n",
      "|Cart Exchange Request           |26112 |\n",
      "|Lost/Stolen Cart                |22707 |\n",
      "|Junk Vehicle On Private Property|22705 |\n",
      "+--------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 104:============================>                           (8 + 8) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "case.groupby('service_request_type').count().sort(col('count').desc()).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516ad75",
   "metadata": {},
   "source": [
    "### 10. What are the top 10 service request types in terms of average days late?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a47a88b",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+------------------+---------------+\n",
      "|service_request_type                  |number_days_late  |number_of_cases|\n",
      "+--------------------------------------+------------------+---------------+\n",
      "|Zoning: Recycle Yard                  |210.89201994318182|132            |\n",
      "|Zoning: Junk Yards                    |200.2051760849428 |262            |\n",
      "|Structure/Housing Maintenance         |190.20707698509807|51             |\n",
      "|Donation Container Enforcement        |171.09115313942624|122            |\n",
      "|Storage of Used Mattress              |163.96812829714287|7              |\n",
      "|Labeling for Used Mattress            |162.43032902285717|7              |\n",
      "|Record Keeping of Used Mattresses     |153.99724039428568|7              |\n",
      "|Signage Requied for Sale of Used Mattr|151.63868055333333|12             |\n",
      "|Traffic Signal Graffiti               |137.64583330000002|16             |\n",
      "|License Requied Used Mattress Sales   |128.79828704142858|7              |\n",
      "+--------------------------------------+------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case.where('case_late').groupBy('service_request_type').\\\n",
    "agg(mean('num_days_late').alias('number_days_late'), count('*').alias('number_of_cases')).\\\n",
    "sort(desc('number_days_late')).\\\n",
    "show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5f100f",
   "metadata": {},
   "source": [
    "### 11. Does number of days late depend on department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e644280e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Reference 'dept_name' is ambiguous, could be: dept_name, dept_name, dept_name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b2/3fdswr7x4v5fhdt54wpcfmdw0000gn/T/ipykernel_16110/2150216522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m (case.filter('case_late')\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dept_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_days_late'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'days_late'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_days_late'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_cases_late'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'days_late'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'days_late'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'days_late'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pyspark/sql/group.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# Columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all exprs should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             jdf = self._jgd.agg(exprs[0]._jc,\n\u001b[0m\u001b[1;32m    119\u001b[0m                                 _to_seq(self.sql_ctx._sc, [c._jc for c in exprs[1:]]))\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Reference 'dept_name' is ambiguous, could be: dept_name, dept_name, dept_name."
     ]
    }
   ],
   "source": [
    "(case.filter('case_late')\n",
    "    .groupby('dept_name')\n",
    "    .agg(mean('num_days_late').alias('days_late'), count('num_days_late').alias('n_cases_late'))\n",
    "    .sort('days_late')\n",
    "    .withColumn('days_late', round(col('days_late'), 1))\n",
    "    .show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38971ae8",
   "metadata": {},
   "source": [
    "### 12. How do number of days late depend on department and request type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff8b555e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Reference 'standardized_dept_name' is ambiguous, could be: standardized_dept_name, standardized_dept_name, standardized_dept_name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b2/3fdswr7x4v5fhdt54wpcfmdw0000gn/T/ipykernel_16110/173413502.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m (\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"case_closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"case_late\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"standardized_dept_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"service_request_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_days_late\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"days_late\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_cases\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pyspark/sql/group.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# Columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all exprs should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             jdf = self._jgd.agg(exprs[0]._jc,\n\u001b[0m\u001b[1;32m    119\u001b[0m                                 _to_seq(self.sql_ctx._sc, [c._jc for c in exprs[1:]]))\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Reference 'standardized_dept_name' is ambiguous, could be: standardized_dept_name, standardized_dept_name, standardized_dept_name."
     ]
    }
   ],
   "source": [
    "(\n",
    "    case.filter(\"case_closed\")\n",
    "    .filter(\"case_late\")\n",
    "    .groupby(\"standardized_dept_name\", \"service_request_type\")\n",
    "    .agg(avg(\"num_days_late\").alias(\"days_late\"), count(\"*\").alias(\"n_cases\"))\n",
    "    .withColumn(\"days_late\", round(col(\"days_late\"), 1))\n",
    "    .sort(col('standardized_dept_name'), col('days_late'))\n",
    "    .show(40, truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f5c8b",
   "metadata": {},
   "source": [
    "### 13. You might have noticed that the latest date in the dataset is fairly far off from the present day. To account for this, replace any occurances of the current time with the maximum date from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c4684872",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = (\n",
    "    case.withColumn('case_opened_date', to_timestamp(col('case_opened_date'), 'M/d/yy H:mm'))\n",
    "    .withColumn('case_closed_date', to_timestamp(col('case_closed_date'), 'M/d/yy H:mm'))\n",
    "    .withColumn('case_due_date', to_timestamp(col('case_due_date'), 'M/d/yy H:mm'))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
